# Example .env file
GEMINI_API_KEY=your_gemini_api_key_here
# Optional: Specify a different Gemini model compatible with the API
# GEMINI_MODEL_NAME="gemini-1.5-flash"

# Model Configuration
# Available Gemini models: gemini-pro, gemini-pro-vision
GEMINI_MODEL_NAME=gemini-pro

# Whisper Model Configuration
# Available models: tiny.en, base.en, small.en, medium.en, large
# Larger models provide better quality but require more computational resources
WHISPER_MODEL_NAME=small.en

# Optional: OpenRouter Fallback Configuration
OPENROUTER_API_KEY="YOUR_OPENROUTER_API_KEY"
# Optional: Specify a different OpenRouter model (check OpenRouter docs for free/compatible models)
# OPENROUTER_MODEL_NAME="nousresearch/nous-hermes-2-mixtral-8x7b-dpo:free"

# Optional: API Base URL (if using a different endpoint)
# GEMINI_API_BASE=https://your-custom-endpoint.com/v1

# Optional: Temperature for text generation (0.0 to 1.0)
# Higher values make output more creative but less focused
# GEMINI_TEMPERATURE=0.7

# Optional: Maximum tokens for response
# MAX_TOKENS=4096